# Echo Audio Browser - Scale-Up Session Handoff

**Created:** 2026-02-11 17:45 UTC
**Purpose:** Everything needed to scale Echo from 16 â†’ 50 episodes
**Previous Session:** Fixed search bugs, improved boundaries, ready for scale

---

## ğŸš€ Quick Start

### Current State
- **16 episodes** indexed (All-In Podcast)
- **438 topics**, **10,217 sentences** in Typesense
- **V3 segmentation** with boundary refinement + conjunction fix
- **Clip extraction** working (WAV â†’ MP3 on demand)
- **Live URL:** Check `TUNNEL_URL.txt` for current cloudflared URL

### Start the Server
```bash
cd ~/clawd/projects/echo-audio-browser
tmux kill-session -t echo 2>/dev/null
tmux new-session -d -s echo "cd ~/clawd/projects/echo-audio-browser && source venv/bin/activate && export OPENAI_API_KEY=\$(cat ~/.clawd/.api-keys/openai.key) && python3 -m uvicorn app.main:app --host 0.0.0.0 --port 8766 --workers 1"
```

### Start the Tunnel
```bash
nohup cloudflared tunnel --url http://localhost:8766 > tunnel.log 2>&1 &
sleep 8
grep -oE "https://[a-z0-9-]+\.trycloudflare\.com" tunnel.log | head -1 > TUNNEL_URL.txt
cat TUNNEL_URL.txt
```

---

## ğŸ“‹ Task: Scale to 50 Episodes

### See: `SCALE_UP_PLAN.md` for detailed plan

### High-Level Steps
1. **Select episodes** â€” Mix of All-In + other podcasts (Lex, Ferriss, etc.)
2. **Download content** â€” yt-dlp for audio + captions
3. **Convert to WAV** â€” Required for accurate clip timestamps
4. **Run indexing pipeline** â€” V3 segmentation (~5-8 min per episode)
5. **Validate quality** â€” Test searches, verify clips

---

## ğŸ”§ Key Files & Architecture

### Indexing Pipeline
```
app/services/
â”œâ”€â”€ pipeline_v3.py          # Main indexing entry point
â”œâ”€â”€ topic_segmentation_v3.py # V3 segmentation with:
â”‚   â”œâ”€â”€ Boundary refinement (LLM picks optimal start/end)
â”‚   â”œâ”€â”€ Conjunction fix (handles "But/And/So" starts)
â”‚   â””â”€â”€ Hallucination detection (validates summaries)
â”œâ”€â”€ sentence_parser.py      # VTT â†’ sentences with NER
â”œâ”€â”€ typesense_indexer.py    # Index to Typesense
â””â”€â”€ clip_extractor.py       # WAV â†’ MP3 clip extraction
```

### Search Pipeline
```
app/services/search_l3.py   # Level 3 commercial-grade search:
â”œâ”€â”€ Phase 1: Query understanding (LLM expands query)
â”œâ”€â”€ Phase 2: Hybrid retrieval (BM25 + vector)
â”œâ”€â”€ Phase 3: LLM reranking (returns topic_id, not index)
â””â”€â”€ Phase 4: Categorization (ABOUT / Also discusses / Related)
```

### Frontend
```
static/index.html           # Single-page app
â”œâ”€â”€ Search â†’ calls /v2/search/l3
â”œâ”€â”€ Results â†’ ABOUT (yellow), Also discusses (cyan), Related
â””â”€â”€ Audio â†’ Redirects to /clip/{episode}?start_ms=X&end_ms=Y
```

---

## ğŸ› Bugs Fixed This Session

### 1. Summary Mismatch Bug
**Problem:** LLM returned wrong indices during reranking, causing mismatched summaries
**Fix:** Changed to return `topic_id` instead of index in reranking
**File:** `app/services/search_l3.py` (lines 335-410)

### 2. Audio Timestamp Bug
**Problem:** Frontend used full MP3 with seek (unreliable), not extracted clips
**Fix:** 
- Backend returns `/clip/{episode}?start_ms=X&end_ms=Y`
- `/clip` endpoint generates clip on demand, redirects to audio file
**Files:** `app/services/search_l3.py`, `app/routers/search.py`, `static/index.html`

### 3. Mid-Sentence Start Bug
**Problem:** Topics could start with "But", "So", etc. without context
**Fix:** Added `_fix_conjunction_starts()` post-processing step
**File:** `app/services/topic_segmentation_v3.py`

---

## ğŸ“ Directory Structure

```
~/clawd/projects/echo-audio-browser/
â”œâ”€â”€ audio/                  # Audio files
â”‚   â”œâ”€â”€ *.wav              # Source (accurate timestamps)
â”‚   â”œâ”€â”€ *.mp3              # Fallback playback
â”‚   â”œâ”€â”€ *.en.vtt           # Transcripts
â”‚   â””â”€â”€ clips/             # Generated MP3 clips (cache)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ topic_embeddings.json  # Cached OpenAI embeddings
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # FastAPI app
â”‚   â”œâ”€â”€ routers/           # API endpoints
â”‚   â””â”€â”€ services/          # Business logic
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html         # Frontend
â”œâ”€â”€ SCALE_UP_PLAN.md       # Detailed scaling plan
â”œâ”€â”€ HANDOFF_SESSION.md     # Previous handoff (V3 features)
â””â”€â”€ TUNNEL_URL.txt         # Current public URL
```

---

## ğŸ”‘ Credentials & Config

### OpenAI API Key
```bash
cat ~/.clawd/.api-keys/openai.key
```

### Typesense
- **Host:** localhost:8108
- **API Key:** See `.env` file
- **Collections:** `topics`, `sentences`

### Environment
```bash
source venv/bin/activate
export OPENAI_API_KEY=$(cat ~/.clawd/.api-keys/openai.key)
```

---

## ğŸ“Š Commands Reference

### Download an Episode
```bash
VIDEO_ID="xxxxxxxxxxx"
yt-dlp -f 'bestaudio[ext=m4a]' -o "audio/${VIDEO_ID}.m4a" --write-auto-subs --sub-lang en "https://youtube.com/watch?v=${VIDEO_ID}"
ffmpeg -i "audio/${VIDEO_ID}.m4a" -ar 44100 -ac 2 "audio/${VIDEO_ID}.wav"
ffmpeg -i "audio/${VIDEO_ID}.m4a" -ab 128k "audio/${VIDEO_ID}.mp3"
```

### Index an Episode
```bash
cd ~/clawd/projects/echo-audio-browser
source venv/bin/activate
export OPENAI_API_KEY=$(cat ~/.clawd/.api-keys/openai.key)
PYTHONPATH=. python3 app/services/pipeline_v3.py audio/VIDEO_ID.en.vtt
```

### Index All Episodes
```bash
for vtt in audio/*.en.vtt; do
    echo "Processing: $vtt"
    PYTHONPATH=. python3 app/services/pipeline_v3.py "$vtt"
    sleep 2
done
```

### Test Search (CLI)
```bash
PYTHONPATH=. python3 -c "
from app.services.search_l3 import search_l3
result = search_l3('your query here', limit=5)
for r in result['about']:
    print(f'{r[\"summary\"][:80]}...')
"
```

### Clear Clip Cache
```bash
rm -rf audio/clips/*.mp3
```

### Check Typesense Stats
```bash
curl -s "http://localhost:8108/collections/topics" -H "X-TYPESENSE-API-KEY: $(grep TYPESENSE_API_KEY .env | cut -d= -f2)" | python3 -m json.tool | grep num_documents
```

---

## âš ï¸ Known Limitations

1. **VTT Quality** â€” YouTube auto-captions can have errors; affects segmentation
2. **Embedding Load Time** â€” ~5 seconds on first search to load embeddings
3. **Clip Generation** â€” First play of a clip has ~2-3s delay for ffmpeg
4. **Memory** â€” Search loads all embeddings; may need optimization at scale

---

## ğŸ¯ Success Criteria for Scale-Up

- [ ] 50 episodes downloaded and converted
- [ ] All episodes indexed with V3 pipeline
- [ ] Search returns relevant results across all content
- [ ] Audio clips play correctly
- [ ] Performance acceptable (< 10s search)
- [ ] Disk space under control

---

## ğŸ“ Questions?

If stuck, check:
1. `SCALE_UP_PLAN.md` â€” Detailed execution plan
2. `HANDOFF_SESSION.md` â€” V3 feature documentation
3. `ARCHITECTURE_REVIEW.md` â€” System design overview
4. Server logs: `tmux capture-pane -t echo -p -S -100`

---

*Ready for scale-up execution!*
